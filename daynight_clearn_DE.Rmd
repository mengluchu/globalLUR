```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=12, fig.height=8, fig.path='Figs/',
                      echo=T, warning=FALSE, message=FALSE)
```

Load data
```{r}

#load("buffer_oq_dense.R")
load("merged_day_night.Rdata")
names(merged)
```

Required packages
```{r, include=F}
ipak <- function(pkg){
 
   new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
   if (length(new.pkg)) 
    install.packages(new.pkg, dependencies = TRUE, repos='http://cran.muenster.r-project.org')
  sapply(pkg, require, character.only = TRUE)
}
packages <- c( "sp","maptools", "MASS" ,"raster", "sf","dplyr", "glmnet","ggplot2" ,"reshape2","lme4" , "tidyr", "RColorBrewer","devtools", "rasterVis","corrplot", "randomForest", "forestFloor","ranger"  )
ipak(packages)
  install_github("mengluchu/globalLUR/globalLUR/globalLUR")
 library(globalLUR)
 ls("package:globalLUR")
```

Get 3 color pallets.
```{r}
colorB = brewer.pal(7,"Greens")
colorG = brewer.pal(11,"PiYG")
colorS = brewer.pal(11, "Spectral")
```

### Data preprocessing:
0) add variables by ID or by rasters (not in this document). 
1) remove unwanted columns or records, 
2) select records (e.g. by country), separate testing and training sets.
3) merge roads 
 

Separate the dataset into training and  test dataset with a fraction (her 80\% of the records are used for training, the rest for testing), "DE" is the two digit for germany. If for world, the sampling uses the fraction per country. 

```{r}
a= globalLUR::sampledf(merged,fraction = 0.8, "DE" )

```

Retrieve test, training, and all variables.  
```{r}
test = a$test
training = a$training
inde_var=a$inde_var
```

Merge roads of different road types, the road length of these road types are aggregated. The original road types are substituted (with keep =T, they are remained). 

```{r}

inde_var = merge_roads(inde_var,c(3,4,5), keep = F)
#numeric country
#inde_var$country=as.numeric(inde_var$country)
```

### Basic data exploration 

Remove the country variable, as this is only for one country. 
```{r}
inde_var=inde_var[,-which(grepl("country",names(inde_var)))]
```

Retrieve the predictors and responses as test and training set, basic statistics can be calculated. This step could be done later and with cautious, as these variables are global variables.  
```{r}
# test and training variables
inde_var_test =  inde_var[test,]
inde_var_train =  inde_var[training,]

# predictors
 xtest_f = inde_var[test,-which(grepl("value_mean|day_value|night_value", names(inde_var)))]
 xtrain_f = inde_var[training,-which(grepl("value_mean|day_value|night_value", names(inde_var)))]

# observations  
  y_train_mean = inde_var_train$value_mean 
  y_train_day = inde_var_train$day_value 
  y_train_night = inde_var_train$night_value 
  
  y_test_mean = inde_var_test$value_mean 
  y_test_day = inde_var_test$night_value 
  y_test_night = inde_var_test$night_value 
   
#geo_traing = buffer_oq_dense$geometry[training]
#geo_test = buffer_oq_dense$geometry[test]
 
summary(y_train_mean)
summary(y_train_day)
summary(y_train_night)
```



Plot the paired correlation, for all the variables.  
 
```{r}
 
s= cor( inde_var )
corrplot(s, method = "ellipse" )
```
  

Training and  test dataset size (number of stations )
```{r}
length(y_train_mean)
length(y_test_mean)

```






Checkt uni-variant R square. Caculate teh rsq for day, night and mean, and bind the columns to form a dataframe for plotting. 
```{r}
#plot_rsq(inde_var[,-which(grepl("value_mean|day_|night_",names(inde_var)))],inde_var$value_mean)
#plot_rsq(inde_var[,-which(grepl("value_mean|day_|night_",names(inde_var)))],inde_var$night_value)

#plot_rsq(inde_var[,-which(grepl("value_mean|day_|night_",names(inde_var)))],inde_var$day_value)

rsqmean = univar_rsq(inde_var[,-which(grepl("value_mean|day_|night_",names(inde_var)))],inde_var$value_mean)

rsqday = univar_rsq(inde_var[,-which(grepl("value_mean|day_|night_",names(inde_var)))],inde_var$day_value)

rsqnight = univar_rsq(inde_var[,-which(grepl("value_mean|day_|night_",names(inde_var)))],inde_var$night_value)

rsqdf= cbind(rsqmean,rsqday,rsqnight, rownames(rsqmean))  
names(rsqdf)= c("mean","day","night","vars")

plot_rsq(rsqdf = rsqdf, varname = "vars")

# use different color and manually 
#a5= melt(rsqdf, id = "vars") 

#ggplot(a5, aes(x=vars, y = value , colour= variable)) +
#  geom_point() + theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) + 
#  scale_colour_manual(values=c(colorS[4], colorB[5], colorG[3]))
 
```

The scatter plots between predictors and responses, in sequence mean, day, night
```{r scatterplot}
pre_mat = inde_var_train[,which(grepl("ROAD|pop|value_mean|day_value|night_value|temp|wind|Rsp|OMI|eleva|coast", names(inde_var_train)))]


scatterplot(pre_mat,"value_mean", "gam")
scatterplot(pre_mat,"day_value", "gam")
scatterplot(pre_mat,"night_value", "gam")
 
 
```



### Modelling
1) LM model
2) Random forest
3) Lasso
4) Mechanical model (nls) 

Extra: 
5) Separate urban/rural hirachical/ two-step linear regression
6) mixed effects regression 

##### LM: linear regression model 

If simply using linear regression, the mean, day, night. Predictors are population, temperature, wind speed, GEOM product, OMI tropo column, elevation, and road buffers. 

i.e. ROAD|population|value_mean|temperature|wind|GEOM product|OMI|elevation. 

Note population is not always significant, though the individual R square for each buffer is high. The prediction for night is much better than for the day


```{r, eval=F}
#(Throw all the predictors in lm, but there are too many irrelavant variables.) 

  # use all variables in LM
   lm3 = lm(y_train_mean~., data = xtrain_f)

```

```{r}
 
pre_mat = inde_var_train[,which(grepl("ROAD|pop|value_mean|temp|wind|Rsp|OMI|eleva|coast", names(inde_var_train )))]
lm3 = lm(value_mean~., data = pre_mat)
summary(lm3) 

error_matrix(y_test_mean,prediction = predict(lm3,newdata =xtest_f))
 

pre_mat = inde_var_train[,which(grepl("ROAD|pop|day_|temp|wind|Rsp|OMI|eleva|coast", names(inde_var_train )))]
lm3 = lm(day_value~., data = pre_mat)
summary(lm3) 
  error_matrix(y_test_day,prediction = predict(lm3,newdata =xtest_f))


pre_mat = inde_var_train[,which(grepl("ROAD|pop|night_|temp|wind|Rsp|OMI|eleva|coast", names(inde_var_train )))]
lm3 = lm(night_value~., data = pre_mat)
summary(lm3) 
  error_matrix(y_test_night,prediction = predict(lm3,newdata =xtest_f))


```

###### Randomforest. The prediction is so far the best.  For night the prediction error is much lower. Also indicated in the validation. 

```{r}
library(ranger) 

pre_mat = inde_var_train[,which(grepl("ROAD|pop|value_mean|temp|wind|Rsp|OMI|eleva|coast", names(inde_var_train)))]
rf3 <- ranger(value_mean~ ., data = pre_mat)
rf3
pre_rf <- predictions(predict(rf3, data =xtest_f ))
#rf_residual <- pre_rf -  rdf_test$NO2
error_matrix(y_test_mean, pre_rf) 

pre_mat = inde_var_train[,which(grepl("ROAD|pop|day_|temp|wind|Rsp|OMI|eleva|coast", names(inde_var_train)))]
rf3 <- ranger(day_value~ ., data = pre_mat)
rf3
pre_rf <- predictions(predict(rf3, data =xtest_f ))
#rf_residual <- pre_rf -  rdf_test$NO2
error_matrix(y_test_day, pre_rf) 

pre_mat = inde_var_train[,which(grepl("ROAD|pop|night_|temp|wind|Rsp|OMI|eleva|coast", names(inde_var_train)))]
rf3 <- ranger(night_value~ ., data = pre_mat)
rf3
pre_rf <- predictions(predict(rf3, data =xtest_f ))
#rf_residual <- pre_rf -  rdf_test$NO2
error_matrix(y_test_night, pre_rf) 


#default = randomForest(y_train~ ., data = pre_mat,ntree=5000,mtry=4,
#                         keep.inbag = T,keep.forest = T)
#ff = forestFloor(default, X=pre_mat)
 
#names(pre_mat)
#Col = fcol(ff,cols=1)
#           plot(ff,col=Col,plot_GOF = T)
```

###### LASSO 

In Sequence, mean, day , night. The predicton errors are much higher than random forest, but used a much simpler model 
The variables selected are slightly different from each other. The variables selected each time are also different. 

```{r}

 
Lasso(inde_var, "value_mean",training, test)
Lasso(inde_var, "day_value",training, test)
Lasso(inde_var, "night_value",training, test)
 
```





 USing the ring of roads. THe road length in each ring could be normalised by the area of the ring (becomes road length density, not done in this model, can choose normalise =T). However, the coefficents of the regression do not increase or decrease with roadrings further away. Looks the 5000m is dominating. If removing this parameter, the 1000m dominates. The coefficients



```{r ring}
## use the ring of roads

## question: what are the roads, road0 are all 0


 
#rmrows = seq(7,34, by = 7)
#roadrings = roadrings[,-rmrows]

 

#lmroadrings_2 = lm(y_train~., data =data.frame(nor_ring[training,8:14]))
#summary(lmroadrings_2)
#plot(coef(lmroadrings_2), typ = "l")
#lmroadrings_3 = lm(y_train~., data =data.frame(nor_ring[training, 22:28]))
#summary(lmroadrings_3)
#plot(coef(lmroadrings_3), typ = "l")

#lmroadrings = lm(y_train~., data =data.frame(nor_ring[training, ]))
#summary(lmroadrings)
#plot(coef(lmroadrings), typ = "l")
 
```

additional variable pop1k, 3k, elevation, sequentially  
```{r}
 

buffers_in = c(0,25,50,100,300,500,1000)
buffers_out = c(25, 50,100,300,500,1000,5000)
distance_center = (buffers_out-buffers_in)/2 + buffers_in

mechanical(inde_var,"day_value","pop1k", distance_centre = distance_centre, training, test)
mechanical(inde_var,"day_value","pop3k", distance_centre = distance_centre, training, test)
mechanical(inde_var,"day_value","elevation", distance_centre = distance_centre, training, test) 


```
coefficients for different road types as a function of road ring for different road types
```{r}


RDring_coef(inde_var,  quote(value_mean)) 

RDring_coef(inde_var,  quote(day_value) )
RDring_coef(inde_var,  quote(night_value)) 

```
coefficients for different road types as a function of road ring for different road types, with pop3k as a variable, for day polution
```{r}
RDring_coef(inde_var,  quote(day_value), pop_var = "pop3k") 
```

 
 
```{r, eval = F}
library(nlstools)
 
 
overview(a1)
 
a1resi= nlsResiduals(a1)
plot(a1resi)
 
```


Separating rural and urban points. Fit a model for Rurual points using 5000m buffer, population, and elevation. Then fit a model for urban points using the prediction of the rural model, and road variables excluding 5000m buffer.
The urban and rurual models are also fit independently for comparison. The rural models include all road variables, elevation and population. 
```{r}
 
var_rural= inde_var%>%filter(Dis2>1000&pop1k<3156)
var_urban= inde_var%>%filter(Dis2<1000|Dis1<500)
nrow(var_rural)
nrow(var_urban)
nrow(inde_var)
names(inde_var)
pre_mat_r = var_rural[,which(grepl("5000|elev|pop", names(var_rural)))] #0.4 with the same variable
pre_mat_u = var_urban[,which(grepl("ROAD|eleva|pop", names(var_urban)))]

trainingR=sample(1:nrow(var_rural),round(nrow(var_rural)*0.8) )
testR=c(1:nrow(var_rural))[-trainingR]

trainingU=sample(1:nrow(var_urban),round(nrow(var_urban)*0.8))
testU=c(1:nrow(var_urban))[-trainingU]

y_train_u=var_urban$value_mean[trainingU] 

y_train_r=var_rural$value_mean[trainingR]
x_train_u = pre_mat_u[trainingU,] 
x_train_r = pre_mat_r[trainingR,] 

y_test_u=var_urban$value_mean[testU]
 
y_test_r=var_rural$value_mean[testR]
x_test_u = pre_mat_u[testU,] 
x_test_r = pre_mat_r[testR,] 

 lm3 = lm(y_train_u~., data = x_train_u)
summary(lm3) 

error_matrix(y_test_u,predict(lm3,newdata =x_test_u))

 lmR = lm(y_train_r~., data = x_train_r)
summary(lmR)
 y_pre = predict(lmR, newdata = x_train_u)
newpre= data.frame(cbind(y_pre,x_train_u[,-which(grepl("5000|elevation|pop", names(x_train_u)))]))
   lm4 = lm(y_train_u~., data = newpre )
summary(lm4) 

#y_excl_test = y_test_u - predict(lmR, newdata = x_test_u)
 y_pre = predict(lmR, newdata = x_test_u) 
test_pre= data.frame(cbind(y_pre,x_test_u ))

error_matrix(y_test_u,predict(lm4,newdata =test_pre))
```

Urban points and roads in random forest
```{r}

pre_mat_u = x_train_u[,which(grepl("ROAD", names(x_train_u)))]
rf3 <- ranger(y_train_u~ ., data = pre_mat_u)
rf3
pre_rf <- predictions(predict(rf3, data =x_test_u ))
#rf_residual <- pre_rf -  rdf_test$NO2
error_matrix(y_test_u, pre_rf)

default = randomForest(y_train_u~ ., data = pre_mat_u,ntree=5000,mtry=4,
                         keep.inbag = T,keep.forest = T)
ff = forestFloor(default, X=x_train_u)
 
Col = fcol(ff,cols=2)
           plot(ff,col=Col,plot_GOF = T)
#           show3d(ff,c(24,19),1,col=Col,plot_GOF = T)
```

Lasso on urban points
```{r}
pre_mat_u = var_urban[,which(grepl("ROAD|pop|temp|wind|Rsp|OMI|eleva|coast", names(var_urban)))]
pre_mat_u = pre_mat_u[trainingU,] 

cvfit <- glmnet::cv.glmnet(as.matrix(pre_mat_u),y_train_u,type.measure = "mse",standardize=TRUE,alpha = 0.5,lower.limit=0)
pre_mat_test = x_test_u[,which(grepl("ROAD", names(x_test_u)))]
  Lassoselected(cvfit)
```

Urban vs. using all
```{r, eval = F}

var_urban %>% gather(VAR, predictors, -value_mean ) %>% ggplot(aes(x=predictors, y = value_mean ))+geom_point()  +facet_wrap(~ VAR, scales = "free") +stat_smooth(method = "lm") +
    theme_bw()


var_rural %>% gather(VAR, predictors, -value_mean ) %>% ggplot(aes(x=predictors, y = value_mean ))+geom_point()  +facet_wrap(~ VAR, scales = "free") +stat_smooth(method = "lm") +
    theme_bw()

inde_var %>% gather(VAR, predictors, -value_mean ) %>% ggplot(aes(x=predictors, y = value_mean ))+geom_point()  +facet_wrap(~ VAR, scales = "free") +stat_smooth(method = "lm") +
    theme_bw()
```

 

 
use urban data only
```{r, eval=F}

roadsonly_u = x_train_u[, which(grepl("ROAD",
                                 names(x_train_u)))] # 25 -50000

ringsonly_u = create_ring(roadsonly_u)
  
b = paste0("Q",rep(1:5, each = 7))
formu1 = as.formula(paste("y_train_u~",
                          paste(names( ringsonly_u)  , "*", b,"*exp( a *", disl  ,")",collapse = "+"), "+d*pop1k", "+c")) 




# form the dataframe 
disdf = data.frame(mapply(rep,distance_center, each = nrow(ringsonly_u) ))
names(disdf)= disl
rdf = cbind(ringsonly_u,disdf, y_train_u=y_train_u ,pop1k = x_train_u$pop1k)           
#rdf = cbind(rdf, OMI_mean_filt =data.frame(xtrain_f)$OMI  )

# model: y = roadring * exp ( dis * a)             
 

a1 =  nls(formu1, data = rdf,start = list(a = -0.001,Q1=0.01, Q2 = 0.001,Q3 = 0.0001,Q4 = 0.0001,Q5=0.00001, c = 0.001, d = 0.001))
 
summary(a1)

roadrings_test =ringsonly[test,]
disdf2= data.frame(mapply(rep,distance_center, each = nrow(roadrings_test) ))
names(disdf2)= disl
rd2 = cbind(ringsonly[test,] , disdf2,pop1k = xtest_f$pop1k)
 
dp = predict(a1,  newdata = rd2)
 
error_matrix(y_test,dp )
coef = coefficients(a1)
 
plot(y_test,typ = "line")
lines(dp , col= "red" )
 
plot( distance_center ,coef[2]*exp(distance_center *coef[1]), typ = "l" , main = "coefficients", ylim=c(0,2e-03) ,col = colorG[1])
lines( distance_center ,coef[3]*exp(distance_center *coef[1]), typ = "l" , main = "coefficients",col = colorG[3])
lines( distance_center ,coef[4]*exp(distance_center *coef[1]), typ = "l" , main = "coefficients",col = colorG[4])
lines( distance_center ,coef[5]*exp(distance_center *coef[1]), typ = "l" , main = "coefficients",col = colorG[5])
lines( distance_center ,coef[6]*exp(distance_center *coef[1]), typ = "l" , main = "coefficients",col = colorG[8])
legend("topright", c("r1","r2","r3","r4","r5"), lty = 1, col= colorG[c(1,3:5,8)])

```
